{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53d0cf15",
   "metadata": {},
   "source": [
    "## Deep Sequence \n",
    " \n",
    "### (a) Deep Sequence Modeling and Categories\n",
    "Deep sequence modeling is essentially applying neural network to problems involving sequential processing of data. Sequence data has memory and comes in many forms such as text, audio, video and financial time series. Thus, requiring a different modeling approaches. Sequence problems can be broadly categorized into the following types,\n",
    "\n",
    "1. one-to-one\n",
    "\n",
    "2. one-to-many\n",
    "\n",
    "3. many-to-one\n",
    "\n",
    "4. many-to-many\n",
    "\n",
    "We’ll see two types of these sequence problem : single feature and multiple features. In the former, each timestep has a single feature and in later, each timestep has multiple features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8bd9677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 11:00:39.405354: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "## Data Retrieval and Preprocessing # Import required libraries \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Import from keras \n",
    "from keras import Sequential \n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "# Ignore warnings \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7261afe",
   "metadata": {},
   "source": [
    "## One-to-One Single Feature\n",
    "\n",
    "In one-to-one sequence problem, there is a single input and a single ouput. We’ll use LSTM network to the sequence problems. Each input consists of one timestep, which in turn contains a single feature (X).\n",
    "\n",
    "The input of the LSTM is always a 3D array ***[batch, timesteps, feature]***. The output of the LSTM could be a 2D array or 3D array depending upon the return_sequences argument If `return_sequence` is False, the output is a 2D array ***[batch, feature]*** If return_sequence is True, the output is a 3D array ***[batch, timesteps, feature]***.\n",
    "\n",
    "- **batch** is the number of samples in the input data (20 in this case), \n",
    "- **timesteps** are the number of timesteps per sample (1 in this case) and,\n",
    "- **feature** correspond to the number of features per timestep (1 in this case).\n",
    "\n",
    "### b) Train a one-to-one sequence LSTM model for a given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d85cdd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "y: [ 10  20  30  40  50  60  70  80  90 100 110 120 130 140 150 160 170 180\n",
      " 190 200]\n"
     ]
    }
   ],
   "source": [
    "# create sample dataset \n",
    "X = np.arange(1,21,1)\n",
    "y = np.arange(10,210,10)\n",
    "\n",
    "print(f'X: {X}') \n",
    "print(f'y: {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24296bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape into 3D \n",
    "X = np.array(X).reshape(20,1,1)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e5644f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 50)                10400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,451\n",
      "Trainable params: 10,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 11:00:43.267385: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# complie model one \n",
    "model_one = Sequential() \n",
    "model_one.add(LSTM(50, activation='relu', input_shape=(1,1))) \n",
    "model_one.add(Dense(1)) \n",
    "model_one.compile(optimizer='adam', loss='mse') \n",
    "print(model_one.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ff3877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.8 s, sys: 6.81 s, total: 56.6 s\n",
      "Wall time: 46.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca69b343a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fit model one \n",
    "model_one.fit(X, y, batch_size=5, epochs=2000, validation_split=0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38e6ed6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Value should be: 300\n",
      "The Prediction is: [[295.91928]]\n"
     ]
    }
   ],
   "source": [
    "# predict the outcome \n",
    "test_input = np.array([30]) \n",
    "test_input = test_input.reshape((1, 1, 1)) # should be in dimension of 3\n",
    "test_output = model_one.predict(test_input, verbose=0) \n",
    "print('True Value should be:', 300)\n",
    "print('The Prediction is:', test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08b45b7",
   "metadata": {},
   "source": [
    "### c) One-to-One Single Feature W/stacked LSTM\n",
    "\n",
    "For the above function and dataset, let’s now train our model with stacked LSTM layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cedaa36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 1, 50)             10400     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,651\n",
      "Trainable params: 30,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# complie model two \n",
    "model_two = Sequential() \n",
    "model_two.add(LSTM(50, \n",
    "                   activation='relu', \n",
    "                   return_sequences=True, \n",
    "                   input_shape=(1, 1)))\n",
    "\n",
    "model_two.add(LSTM(50, activation='relu'))\n",
    "model_two.add(Dense(1))\n",
    "\n",
    "model_two.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "print(model_two.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a9cb134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 1s, sys: 9.19 s, total: 1min 10s\n",
      "Wall time: 53.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca4bb1cfa0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fit model two \n",
    "model_two.fit(X, y, batch_size=5, epochs=2000, validation_split=0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1bb0a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Value should be: 300\n",
      "The Prediction is: [[299.4031]]\n",
      "Adding one more LSTM layer seems make the prediction more accurate.\n"
     ]
    }
   ],
   "source": [
    "# predict the outcome \n",
    "test_output = model_two.predict(test_input, verbose=0) \n",
    "print('True Value should be:', 300)\n",
    "print('The Prediction is:', test_output)\n",
    "print('Adding one more LSTM layer seems make the prediction more accurate.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feddfc15",
   "metadata": {},
   "source": [
    "### d) One-to-One Multiple Feature\n",
    "\n",
    "In the above examples, each input sample had one timestep where each timestep had one feature. In this example, we will model a one-to-one sequence problem when the input timesteps **have multiple features**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a953b9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1: [ 2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40]\n",
      "X2: [ 3  6  9 12 15 18 21 24 27 30 33 36 39 42 45 48 51 54 57 60]\n",
      "y: [6, 24, 54, 96, 150, 216, 294, 384, 486, 600, 726, 864, 1014, 1176, 1350, 1536, 1734, 1944, 2166, 2400]\n"
     ]
    }
   ],
   "source": [
    "# create sample dataset \n",
    "X1 = np.arange(2,42,2)\n",
    "X2 = np.arange(3, 63, 3) \n",
    "\n",
    "y = [6]\n",
    "for i in range(19):\n",
    "    y.append(y[i]+18 + 12*i)\n",
    "\n",
    "\n",
    "print(f'X1: {X1}') \n",
    "print(f'X2: {X2}') \n",
    "print(f'y: {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbcea45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  3]\n",
      " [ 4  6]\n",
      " [ 6  9]\n",
      " [ 8 12]\n",
      " [10 15]\n",
      " [12 18]\n",
      " [14 21]\n",
      " [16 24]\n",
      " [18 27]\n",
      " [20 30]\n",
      " [22 33]\n",
      " [24 36]\n",
      " [26 39]\n",
      " [28 42]\n",
      " [30 45]\n",
      " [32 48]\n",
      " [34 51]\n",
      " [36 54]\n",
      " [38 57]\n",
      " [40 60]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20, 1, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a feature matrix \n",
    "X = np.c_[X1, X2]\n",
    "print(X)\n",
    "\n",
    "# reshape into 3D \n",
    "X = np.array(X).reshape(20,1,2)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee821843",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   6   24   54   96  150  216  294  384  486  600  726  864 1014 1176\n",
      " 1350 1536 1734 1944 2166 2400]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to array \n",
    "y = np.array(y)\n",
    "\n",
    "print(y)\n",
    "\n",
    "# check the shape \n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "242a1187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 50)                10600     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,121\n",
      "Trainable params: 11,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# complie model three \n",
    "model_three = Sequential() \n",
    "# the input-set has three dimension. the first is ignored, the second is # period, the third means the # features\n",
    "model_three.add(LSTM(50, activation='relu', input_shape=(1, 2)))   \n",
    "model_three.add(Dense(10, activation='relu'))  # there is one more layer\n",
    "model_three.add(Dense(1)) \n",
    "model_three.compile(optimizer='adam', loss='mse') \n",
    "print(model_three.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f5cd049",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.9 s, sys: 8.33 s, total: 1min 1s\n",
      "Wall time: 48.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca4d2050d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fit model three \n",
    "model_three.fit(X, y, batch_size=5, epochs=2000, validation_split=0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b942c53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3580.767]]\n"
     ]
    }
   ],
   "source": [
    "# predict the outcome \n",
    "test_input = np.array([55,80]) \n",
    "test_input = test_input.reshape((1, 1, 2)) \n",
    "test_output = model_three.predict(test_input, verbose=0) \n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34490229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The True Value should be: 2646\n",
      "The Prediction is: [[2455.1038]]\n"
     ]
    }
   ],
   "source": [
    "# predict the outcome \n",
    "test_input = np.array([42,63]) \n",
    "test_input = test_input.reshape((1, 1, 2)) \n",
    "test_output = model_three.predict(test_input, verbose=0) \n",
    "print('The True Value should be:', 2646)\n",
    "print('The Prediction is:', test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b819c3c",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9b8c9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 1, 200)            162400    \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 200)               320800    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 50)                10050     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 493,771\n",
      "Trainable params: 493,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# complie model four, with multi-layers (two LSTM + two layers + one output layer to 1\n",
    "model_four = Sequential() \n",
    "model_four.add(LSTM(200, activation='relu', return_sequences=True, input_shape=(1, 2)))\n",
    "\n",
    "model_four.add(LSTM(200, activation='relu')) \n",
    "model_four.add(Dense(50, activation='relu')) \n",
    "model_four.add(Dense(10, activation='relu')) \n",
    "model_four.add(Dense(1))\n",
    "\n",
    "model_four.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "print(model_four.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dce05588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 48s, sys: 27 s, total: 2min 15s\n",
      "Wall time: 1min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca4d14f0d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fit model four \n",
    "model_four.fit(X, y, batch_size=5, epochs=2000, validation_split=0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70973d7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2315.4492]]\n"
     ]
    }
   ],
   "source": [
    "# predict the outcome \n",
    "test_output = model_four.predict(test_input, verbose=0) \n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb17f468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The True Value should be: 2646\n",
      "The Prediction is: [[2315.4492]]\n"
     ]
    }
   ],
   "source": [
    "# predict the outcome \n",
    "test_input = np.array([42,63]) \n",
    "test_input = test_input.reshape((1, 1, 2)) \n",
    "test_output = model_four.predict(test_input, verbose=0) \n",
    "print('The True Value should be:', 2646)\n",
    "print('The Prediction is:', test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429ec525",
   "metadata": {},
   "source": [
    "Note: The data is not treated for feature scaling or in/out sample as the objective here is to showcase the application of sequence modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4e197e",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
